{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic Transformations\n",
    "\n",
    "## Overview of Basic Transformations\n",
    "\n",
    "Let us define problem statements to learn more about Data Frame APIs. We will try to cover filtering, aggregations and sorting as part of solutions for these problem statements.\n",
    "* Get total number of flights as well as number of flights which are delayed in departure and number of flights delayed in arrival. \n",
    "  * Output should contain 3 columns - **FlightCount**, **DepDelayedCount**, **ArrDelayedCount**\n",
    "* Get number of flights which are delayed in departure and number of flights delayed in arrival for each day along with number of flights departed for each day. \n",
    "  * Output should contain 4 columns - **FlightDate**, **FlightCount**, **DepDelayedCount**, **ArrDelayedCount**\n",
    "  * **FlightDate** should be of **YYYY-MM-dd** format.\n",
    "  * Data should be **sorted** in ascending order by **flightDate**\n",
    "* Get all the flights which are departed late but arrived early (**IsArrDelayed is NO**).\n",
    "  * Output should contain - **FlightCRSDepTime**, **UniqueCarrier**, **FlightNum**, **Origin**, **Dest**, **DepDelay**, **ArrDelay**\n",
    "  * **FlightCRSDepTime** need to be computed using **Year**, **Month**, **DayOfMonth**, **CRSDepTime**\n",
    "  * **FlightCRSDepTime** should be displayed using **YYYY-MM-dd HH:mm** format.\n",
    "  * Output should be sorted by **FlightCRSDepTime** and then by the difference between **DepDelay** and **ArrDelay**\n",
    "  * Also get the count of such flights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Starting Spark Context\n",
    "\n",
    "Let us start spark context for this Notebook so that we can execute the code provided."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "import getpass\n",
    "username = getpass.getuser()\n",
    "\n",
    "spark = SparkSession. \\\n",
    "    builder. \\\n",
    "    config('spark.ui.port', '0'). \\\n",
    "    enableHiveSupport(). \\\n",
    "    appName(f'{username} | Python - Basic Transformations'). \\\n",
    "    master('yarn'). \\\n",
    "    getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " \n",
    "## Overview of Filtering\n",
    "Let us understand few important details related to filtering before we get into the solution\n",
    "* Filtering can be done either by using `filter` or `>where`. These are like synonyms to each other.\n",
    "* When it comes to the condition, we can either pass it in **SQL Style** or **Data Frame Style**.\n",
    "* Example for SQL Style - `airlines.filter(\"IsArrDelayed = 'YES'\").show() or airlines.where(\"IsArrDelayed = 'YES'\").show()`\n",
    "* Example for Data Frame Style - `airlines.filter(airlines[\"IsArrDelayed\"] == 'YES').show()</mark> or <mark>airlines.filter(airlines.IsArrDelayed == 'YES').show()`. We can also use where instead of filter.\n",
    "* Here are the other operations we can perform to filter the data - `!=`, `>`, `<`>, `>=`, `<=`, `LIKE`, `BETWEEN` with `AND`\n",
    "* If we have to validate against multiple columns then we need to use boolean operations such as `AND` and `OR`.\n",
    "* If we have to compare each column value with multiple values then we can use the `IN` operator.\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tasks\n",
    "\n",
    "Let us perform some tasks to understand filtering in detail. Solve all the problems by passing  conditions using both SQL Style as well as API Style.\n",
    "\n",
    "* Read the data for the month of 2008 January."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "airlines_path = \"/public/airlines_all/airlines-part/flightmonth=200801\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "airlines = spark. \\\n",
    "    read. \\\n",
    "    parquet(airlines_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "airlines.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Get count of flights which are departed late at origin and reach destination early or on time.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "airlines. \\\n",
    "    filter(\"IsDepDelayed = 'YES' AND IsArrDelayed = 'NO'\"). \\\n",
    "    count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* API Style"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "airlines. \\\n",
    "    filter((col(\"IsDepDelayed\") == \"YES\") & \n",
    "           (col(\"IsArrDelayed\") == \"NO\")\n",
    "          ). \\\n",
    "    count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "airlines. \\\n",
    "    filter((airlines[\"IsDepDelayed\"] == \"YES\") & \n",
    "           (airlines.IsArrDelayed == \"NO\")\n",
    "          ). \\\n",
    "    count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Get count of flights which are departed late from origin by more than 60 minutes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "airlines. \\\n",
    "    filter(\"DepDelay > 60\"). \\\n",
    "    count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "* API Style"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col\n",
    "\n",
    "airlines. \\\n",
    "    filter(col(\"DepDelay\") > 60). \\\n",
    "    count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Get count of flights which are departed early or on time but arrive late by at least 15 minutes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "airlines. \\\n",
    "    filter(\"IsDepDelayed = 'NO' AND ArrDelay >= 15\"). \\\n",
    "    count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* API Style"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col\n",
    "\n",
    "airlines. \\\n",
    "    filter((col(\"IsDepDelayed\") == \"NO\") & (col(\"ArrDelay\") >= 15)). \\\n",
    "    count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Get count of flights departed from following major airports - ORD, DFW, ATL, LAX, SFO."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%% \n"
    }
   },
   "outputs": [],
   "source": [
    "airlines. \\\n",
    "    filter(\"Origin IN ('ORD', 'DFW', 'ATL', 'LAX', 'SFO')\"). \\\n",
    "    count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "airlines.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* API Style"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col\n",
    "c = col('x')\n",
    "help(c.isin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col\n",
    "\n",
    "airlines. \\\n",
    "    filter(col(\"Origin\").isin(\"ORD\", \"DFW\", \"ATL\", \"LAX\", \"SFO\")). \\\n",
    "    count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Add a column FlightDate by using Year, Month and DayOfMonth. Format should be **yyyyMMdd**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, concat, lpad\n",
    "\n",
    "airlines. \\\n",
    "    withColumn(\"FlightDate\",\n",
    "                concat(col(\"Year\"),\n",
    "                       lpad(col(\"Month\"), 2, \"0\"),\n",
    "                       lpad(col(\"DayOfMonth\"), 2, \"0\")\n",
    "                      )\n",
    "              ). \\\n",
    "    show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Get count of flights departed late between 2008 January 1st to January 9th using FlightDate.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, concat, lpad\n",
    "\n",
    "airlines. \\\n",
    "    withColumn(\"FlightDate\",\n",
    "               concat(col(\"Year\"),\n",
    "                      lpad(col(\"Month\"), 2, \"0\"),\n",
    "                      lpad(col(\"DayOfMonth\"), 2, \"0\")\n",
    "                     )\n",
    "              ). \\\n",
    "    filter(\"IsDepDelayed = 'YES' AND FlightDate LIKE '2008010%'\"). \\\n",
    "    count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, concat, lpad\n",
    "\n",
    "airlines. \\\n",
    "    withColumn(\"FlightDate\",\n",
    "               concat(col(\"Year\"),\n",
    "                      lpad(col(\"Month\"), 2, \"0\"),\n",
    "                      lpad(col(\"DayOfMonth\"), 2, \"0\")\n",
    "                     )\n",
    "              ). \\\n",
    "    filter(\"\"\"\n",
    "           IsDepDelayed = 'YES' AND \n",
    "           FlightDate BETWEEN 20080101 AND 20080109\n",
    "          \"\"\"). \\\n",
    "    count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* API Style"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col\n",
    "c = col('x')\n",
    "help(c.like)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, concat, lpad\n",
    "\n",
    "airlines. \\\n",
    "    withColumn(\"FlightDate\",\n",
    "               concat(col(\"Year\"),\n",
    "                      lpad(col(\"Month\"), 2, \"0\"),\n",
    "                      lpad(col(\"DayOfMonth\"), 2, \"0\")\n",
    "                     )\n",
    "              ). \\\n",
    "    filter((col(\"IsDepDelayed\") == \"YES\") & \n",
    "           (col(\"FlightDate\").like(\"2008010%\"))\n",
    "          ). \\\n",
    "    count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col\n",
    "c = col('x')\n",
    "help(c.between)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, concat, lpad\n",
    "\n",
    "airlines. \\\n",
    "    withColumn(\"FlightDate\",\n",
    "               concat(col(\"Year\"),\n",
    "                      lpad(col(\"Month\"), 2, \"0\"),\n",
    "                      lpad(col(\"DayOfMonth\"), 2, \"0\")\n",
    "                     )\n",
    "              ). \\\n",
    "    filter((col(\"IsDepDelayed\") == \"YES\") & \n",
    "           (col(\"FlightDate\").between(\"20080101\", \"20080109\"))\n",
    "          ). \\\n",
    "    count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Get number of flights departed late on Sundays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = [('X',)]\n",
    "df = spark.createDataFrame(l, \"dummy STRING\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import current_date\n",
    "df.select(current_date()).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import date_format\n",
    "\n",
    "df.select(current_date(), date_format(current_date(), 'EE')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, concat, lpad\n",
    "\n",
    "airlines. \\\n",
    "    withColumn(\"FlightDate\",\n",
    "               concat(col(\"Year\"),\n",
    "                      lpad(col(\"Month\"), 2, \"0\"),\n",
    "                      lpad(col(\"DayOfMonth\"), 2, \"0\")\n",
    "                     )\n",
    "              ). \\\n",
    "    filter(\"\"\"\n",
    "           IsDepDelayed = 'YES' AND \n",
    "           date_format(to_date(FlightDate, 'yyyyMMdd'), 'EEEE') = 'Sunday'\n",
    "           \"\"\"). \\\n",
    "    count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* API Style"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, concat, lpad, date_format, to_date\n",
    "\n",
    "airlines. \\\n",
    "    withColumn(\"FlightDate\",\n",
    "               concat(col(\"Year\"),\n",
    "                      lpad(col(\"Month\"), 2, \"0\"),\n",
    "                      lpad(col(\"DayOfMonth\"), 2, \"0\")\n",
    "                     )\n",
    "              ). \\\n",
    "    filter((col(\"IsDepDelayed\") == \"YES\") &\n",
    "           (date_format(\n",
    "               to_date(\"FlightDate\", \"yyyyMMdd\"), \"EEEE\"\n",
    "           ) == \"Sunday\")\n",
    "          ). \\\n",
    "    count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview of Aggregations\n",
    "\n",
    "Let us go through the details related to aggregation using Spark.\n",
    "\n",
    "* We can perform total aggregations directly on Dataframe or we can perform aggregations after grouping by a key(s).\n",
    "* Here are the APIs which we typically use to group the data using a key.\n",
    "  * groupBy\n",
    "  * rollup\n",
    "  * cube\n",
    "* Here are the functions which we typically use to perform aggregations.\n",
    "  * count\n",
    "  * sum, avg\n",
    "  * min, max\n",
    "* If we want to provide aliases to the aggregated fields then we have to use `agg` after `groupBy`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview of Sorting\n",
    "\n",
    "Let us understand how to sort the data in a Data Frame.\n",
    "* We can use `orderBy` or `sort` to sort the data.\n",
    "* We can perform composite sorting by passing multiple columns or expressions.\n",
    "* By default data is sorted in ascending order, we can change it to descending by applying `desc()` function on the column or expression."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solutions - Problem 1\n",
    "Get total number of flights as well as number of flights which are delayed in departure and number of flights delayed in arrival. \n",
    "* Output should contain 3 columns - **FlightCount**, **DepDelayedCount**, **ArrDelayedCount**\n",
    "\n",
    "### Reading airlines data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "airlines_path = \"/public/airlines_all/airlines-part/flightmonth=200801\"\n",
    "\n",
    "airlines = spark. \\\n",
    "    read. \\\n",
    "    parquet(airlines_path)\n",
    "\n",
    "airlines.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get flights with delayed arrival"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# SQL Style\n",
    "airlines.filter(\"IsArrDelayed = 'YES'\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Data Frame Style\n",
    "airlines.filter(airlines[\"IsArrDelayed\"] == 'YES').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "airlines.filter(airlines.IsArrDelayed == 'YES').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get delayed counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Departure Delayed Count\n",
    "airlines. \\\n",
    "    filter(airlines.IsDepDelayed == \"YES\"). \\\n",
    "    count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Arrival Delayed Count\n",
    "airlines. \\\n",
    "    filter(airlines.IsArrDelayed == \"YES\"). \\\n",
    "    count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "airlines. \\\n",
    "    filter(\"IsDepDelayed = 'YES' OR IsArrDelayed = 'YES'\"). \\\n",
    "    select('Year', 'Month', 'DayOfMonth', \n",
    "           'FlightNum', 'IsDepDelayed', 'IsArrDelayed'\n",
    "          ). \\\n",
    "    show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Both Departure Delayed and Arrival Delayed\n",
    "from pyspark.sql.functions import col, lit, count, sum, expr\n",
    "airlines. \\\n",
    "    agg(count(lit(1)).alias(\"FlightCount\"),\n",
    "        sum(expr(\"CASE WHEN IsDepDelayed = 'YES' THEN 1 ELSE 0 END\")).alias(\"DepDelayedCount\"),\n",
    "        sum(expr(\"CASE WHEN IsArrDelayed = 'YES' THEN 1 ELSE 0 END\")).alias(\"ArrDelayedCount\")\n",
    "       ). \\\n",
    "    show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Solutions - Problem 2\n",
    "\n",
    "Get number of flights which are delayed in departure and number of flights delayed in arrival for each day along with number of flights departed for each day. \n",
    "\n",
    "* Output should contain 4 columns - **FlightDate**, **FlightCount**, **DepDelayedCount**, **ArrDelayedCount**\n",
    "* **FlightDate** should be of **YYYY-MM-dd** format.\n",
    "*   Data should be **sorted** in ascending order by **flightDate**\n",
    "\n",
    "### Grouping Data by Flight Date\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import lit, concat, lpad\n",
    "airlines. \\\n",
    "  groupBy(concat(\"Year\", lit(\"-\"), \n",
    "                 lpad(\"Month\", 2, \"0\"), lit(\"-\"), \n",
    "                 lpad(\"DayOfMonth\", 2, \"0\")).\n",
    "          alias(\"FlightDate\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting Counts by FlightDate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import lit, concat, lpad, count\n",
    "\n",
    "airlines. \\\n",
    "    groupBy(concat(\"Year\", lit(\"-\"), \n",
    "                   lpad(\"Month\", 2, \"0\"), lit(\"-\"), \n",
    "                   lpad(\"DayOfMonth\", 2, \"0\")).\n",
    "            alias(\"FlightDate\")). \\\n",
    "    agg(count(lit(1)).alias(\"FlightCount\")). \\\n",
    "    show(31)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alternative to get the count with out using agg\n",
    "# We will not be able to provide alias for aggregated fields\n",
    "from pyspark.sql.functions import lit, concat, lpad\n",
    "\n",
    "airlines. \\\n",
    "    groupBy(concat(\"Year\", lit(\"-\"), \n",
    "                   lpad(\"Month\", 2, \"0\"), lit(\"-\"), \n",
    "                   lpad(\"DayOfMonth\", 2, \"0\")).\n",
    "            alias(\"FlightDate\")). \\\n",
    "    count(). \\\n",
    "    show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting total as well as delayed counts for each day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import lit, concat, lpad, count, sum, expr\n",
    "\n",
    "airlines. \\\n",
    "    groupBy(concat(\"Year\", lit(\"-\"), \n",
    "                   lpad(\"Month\", 2, \"0\"), lit(\"-\"), \n",
    "                   lpad(\"DayOfMonth\", 2, \"0\")).\n",
    "            alias(\"FlightDate\")). \\\n",
    "    agg(count(lit(1)).alias(\"FlightCount\"),\n",
    "        sum(expr(\"CASE WHEN IsDepDelayed = 'YES' THEN 1 ELSE 0 END\")).alias(\"DepDelayedCount\"),\n",
    "        sum(expr(\"CASE WHEN IsArrDelayed = 'YES' THEN 1 ELSE 0 END\")).alias(\"ArrDelayedCount\")\n",
    "       ). \\\n",
    "    show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sorting Data By FlightDate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(airlines.sort)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(airlines.orderBy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import lit, concat, lpad, sum, expr\n",
    "airlines. \\\n",
    "    groupBy(concat(\"Year\", lit(\"-\"), \n",
    "                   lpad(\"Month\", 2, \"0\"), lit(\"-\"), \n",
    "                   lpad(\"DayOfMonth\", 2, \"0\")).\n",
    "            alias(\"FlightDate\")). \\\n",
    "    agg(count(lit(1)).alias(\"FlightCount\"),\n",
    "        sum(expr(\"CASE WHEN IsDepDelayed = 'YES' THEN 1 ELSE 0 END\")).alias(\"DepDelayedCount\"),\n",
    "        sum(expr(\"CASE WHEN IsArrDelayed = 'YES' THEN 1 ELSE 0 END\")).alias(\"ArrDelayedCount\")\n",
    "       ). \\\n",
    "    orderBy(\"FlightDate\"). \\\n",
    "    show(31)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sorting Data in descending order by count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import lit, concat, lpad, sum, expr, col\n",
    "airlines. \\\n",
    "    groupBy(concat(\"Year\", lit(\"-\"), \n",
    "                   lpad(\"Month\", 2, \"0\"), lit(\"-\"), \n",
    "                   lpad(\"DayOfMonth\", 2, \"0\")).\n",
    "            alias(\"FlightDate\")). \\\n",
    "    agg(count(lit(1)).alias(\"FlightCount\"),\n",
    "        sum(expr(\"CASE WHEN IsDepDelayed = 'YES' THEN 1 ELSE 0 END\")).alias(\"DepDelayedCount\"),\n",
    "        sum(expr(\"CASE WHEN IsArrDelayed = 'YES' THEN 1 ELSE 0 END\")).alias(\"ArrDelayedCount\")\n",
    "       ). \\\n",
    "    orderBy(col(\"FlightCount\").desc()). \\\n",
    "    show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solutions - Problem 3\n",
    "Get all the flights which are departed late but arrived early (**IsArrDelayed is NO**).\n",
    "* Output should contain - **FlightCRSDepTime**, **UniqueCarrier**, **FlightNum**, **Origin**, **Dest**, **DepDelay**, **ArrDelay**\n",
    "* **FlightCRSDepTime** need to be computed using **Year**, **Month**, **DayOfMonth**, **CRSDepTime**\n",
    "* **FlightCRSDepTime** should be displayed using **YYYY-MM-dd HH:mm** format.\n",
    "* Output should be sorted by **FlightCRSDepTime** and then by the difference between **DepDelay** and **ArrDelay**\n",
    "* Also get the count of such flights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "airlines.select('Year', 'Month', 'DayOfMonth', 'CRSDepTime').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = [(2008, 1, 23, 700),\n",
    "     (2008, 1, 10, 1855),\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.createDataFrame(l, \"Year INT, Month INT, DayOfMonth INT, DepTime INT\")\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import substring\n",
    "df.select(substring(col('DepTime'), -2, 2)). \\\n",
    "    show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.select(\"DepTime\", date_format(lpad('DepTime', 4, \"0\"), 'HH:mm')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(substring)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.select(substring(col('DepTime'), 1, length(col('DepTime').cast('string')))). \\\n",
    "    show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import lit, col, concat, lpad, sum, expr\n",
    "\n",
    "flightsFiltered = airlines. \\\n",
    "    filter(\"IsDepDelayed = 'YES' AND IsArrDelayed = 'NO'\"). \\\n",
    "    select(concat(\"Year\", lit(\"-\"), \n",
    "                  lpad(\"Month\", 2, \"0\"), lit(\"-\"), \n",
    "                  lpad(\"DayOfMonth\", 2, \"0\"), lit(\" \"),\n",
    "                  lpad(\"CRSDepTime\", 4, \"0\")\n",
    "                 ).alias(\"FlightCRSDepTime\"),\n",
    "           \"UniqueCarrier\", \"FlightNum\", \"Origin\", \n",
    "           \"Dest\", \"DepDelay\", \"ArrDelay\"\n",
    "          ). \\\n",
    "    orderBy(\"FlightCRSDepTime\", col(\"DepDelay\") - col(\"ArrDelay\")). \\\n",
    "    show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Getting Count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import lit, col, concat, lpad, sum, expr\n",
    "\n",
    "flightsFiltered = airlines. \\\n",
    "    filter(\"IsDepDelayed = 'YES' AND IsArrDelayed = 'NO'\"). \\\n",
    "    select(concat(\"Year\", lit(\"-\"), \n",
    "                  lpad(\"Month\", 2, \"0\"), lit(\"-\"), \n",
    "                  lpad(\"DayOfMonth\", 2, \"0\"), lit(\" \"),\n",
    "                  lpad(\"CRSDepTime\", 4, \"0\")\n",
    "                 ).alias(\"FlightCRSDepTime\"),\n",
    "           \"UniqueCarrier\", \"FlightNum\", \"Origin\", \n",
    "           \"Dest\", \"DepDelay\", \"ArrDelay\"\n",
    "          ). \\\n",
    "    count()\n",
    "\n",
    "flightsFiltered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Pyspark 2",
   "language": "python",
   "name": "pyspark2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": [
     "\n",
     "\n",
     "\n"
    ]
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
